{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pprint\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILMCLUB_FOLDER = r\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\movies\\\\film_club_data\\\\\"\n",
    "PERSONALPROFILES_FOLDER = r\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\movies\\\\personal_profile_data\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(r\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\movies\\\\tmdb_auth.env\")\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "access_token = os.getenv(\"ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMDB API Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold = '''\n",
    "tmdb_url = \"https://api.themoviedb.org/3/account/21623434/rated/movies?language=en-US&page=1&sort_by=created_at.asc\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {access_token}\"\n",
    "}\n",
    "'''\n",
    "\n",
    "#response = requests.get(tmdb_url, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = json.loads(response.text)\n",
    "#data['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Letterboxd Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract raw HTML data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads through a Letterboxd list and gets the url for each movie in it\n",
    "\n",
    "def get_film_urls_lbxdlist(list_url):\n",
    "    content = requests.get(list_url).text\n",
    "    soup = BeautifulSoup(content, 'html')\n",
    "\n",
    "    url_list = [div['data-target-link'] for div in soup.find_all('div', class_='film-poster')]\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through all the pages of films watched in a user's account and gets the urls of each one\n",
    "\n",
    "def get_film_urls_lbxduser(username):\n",
    "    pages = int(\n",
    "        BeautifulSoup(\n",
    "            requests.get(f'https://letterboxd.com/{username}/films/').text, 'html.parser')\n",
    "            .find_all('li', 'paginate-page')[-1].get_text()\n",
    "        )\n",
    "\n",
    "    url_list = []\n",
    "    for page in range(1, (pages+1)):\n",
    "        print(f\"Extracting page {page} out of {pages}.\")\n",
    "        url = f'https://letterboxd.com/{username}/films/page/{page}/'\n",
    "        content = requests.get(url).text\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "        page_url_list = [div['data-target-link'] for div in soup.find_all('div', 'film-poster')]\n",
    "        url_list += page_url_list\n",
    "    \n",
    "    print(\"Finished.\")\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the complete, raw HTML fom a URL\n",
    "\n",
    "def get_raw_film_html(film_url):\n",
    "    url = \"https://letterboxd.com\" + film_url\n",
    "    content = requests.get(url).text\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures general data and metadata about the film \n",
    "\n",
    "def get_general_film_data(soup):\n",
    "    duration_string = soup.find(class_='text-footer').get_text().replace('\\xa0', ' ').strip()\n",
    "\n",
    "    general_data = {\n",
    "        'letterboxd_id': soup.find(id='backdrop')['data-film-id'],\n",
    "        'letterboxd_shorttitle': soup.find('h1', class_='filmtitle').get_text(),\n",
    "        'letterboxd_longtitle': soup.find(property='og:title')['content'],\n",
    "        'letterboxd_slug': soup.find(id='backdrop')['data-film-slug'],\n",
    "        'letterboxd_url': soup.find(property='og:url')['content'],\n",
    "        'imdb_url': '',\n",
    "        'tmdb_url': soup.find('a', {'data-track-action': 'TMDb'})['href'],\n",
    "        'tmdb_id': '',\n",
    "        'release_year': re.search(r\"\\((\\d{4})\\)\", soup.find('meta', attrs={'name': 'twitter:title'})['content']).group(1),\n",
    "        'duration': '',\n",
    "        'avg_rating': ''\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        general_data['duration'] = re.search(r'(\\d+)\\s+mins', duration_string).group(1)\n",
    "    except:\n",
    "        general_data['duration'] = '-1'\n",
    "    \n",
    "    try:\n",
    "        general_data['avg_rating'] = soup.find('meta', attrs={'name': 'twitter:data2'})['content'].split(' out')[0]\n",
    "    except:\n",
    "        general_data['avg_rating'] = '-1'\n",
    "\n",
    "    try:\n",
    "        general_data['imdb_url'] = soup.find('a', {'data-track-action': 'IMDb'})['href']\n",
    "    except:\n",
    "        general_data['imdb_url'] = ''\n",
    "\n",
    "    general_data['tmdb_id'] = general_data['tmdb_url'].split('/')[-2]\n",
    "\n",
    "    return general_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's cast\n",
    "\n",
    "def get_film_cast(soup):\n",
    "    cast_list = []\n",
    "\n",
    "    try:\n",
    "        cast = soup.find(name='div', class_='cast-list').find_all('a', class_='tooltip')\n",
    "\n",
    "        for member in cast:\n",
    "            cast_member_info = {\n",
    "                'name': member.get_text(strip=True),\n",
    "                'link': member['href']\n",
    "                #'character_name': member['title']\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                cast_member_info['character_name'] = member['title']\n",
    "            except:\n",
    "                cast_member_info['character_name'] = None\n",
    "            cast_list.append(cast_member_info)\n",
    "    except:\n",
    "        cast_list = []\n",
    "\n",
    "    return cast_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's crew\n",
    "\n",
    "def get_film_crew(soup):\n",
    "    crew_list = []\n",
    "\n",
    "    try:\n",
    "        crew = soup.find(id='tab-crew').find_all('a')\n",
    "\n",
    "        for member in crew:\n",
    "            split_link = member['href'].split('/')\n",
    "            \n",
    "            crew_member_info = {\n",
    "                'name': member.get_text(strip=True),\n",
    "                'role': split_link[1],\n",
    "                'link': member['href'],\n",
    "            }\n",
    "            crew_list.append(crew_member_info)\n",
    "    except:\n",
    "        crew_list = []\n",
    "    \n",
    "    return crew_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about other details concerning the movie\n",
    "\n",
    "def get_film_details(soup):\n",
    "    details_list = []\n",
    "    details = soup.find(id='tab-details').find_all('a')\n",
    "\n",
    "    for detail in details:\n",
    "        split_link = detail['href'].split('/')\n",
    "\n",
    "        detail_info = {\n",
    "            'key': '',\n",
    "            'value': detail.get_text(strip=True),\n",
    "            'link': detail['href']\n",
    "        }\n",
    "\n",
    "        if 'studio' in detail['href']:\n",
    "            detail_info['key'] = 'studio'\n",
    "        elif 'country' in detail['href']:\n",
    "            detail_info['key'] = 'country'\n",
    "        elif 'language' in detail['href']:\n",
    "            detail_info['key'] = 'language'\n",
    "        else:\n",
    "            detail_info['key'] = 'ERROR'\n",
    "        details_list.append(detail_info)\n",
    "\n",
    "    return details_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the raw HTML. extracts and structures data about the movie's genres and themes\n",
    "\n",
    "def get_film_genres(soup):\n",
    "    genres = [a_tag.get_text(strip=True) for a_tag in soup.find(id='tab-genres').find_all('a')]\n",
    "\n",
    "    return genres[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a loop using the previous functions to extract all the relevant data and unify it in a dict\n",
    "\n",
    "def get_complete_film_data(film_url):\n",
    "    film_soup = get_raw_film_html(film_url)\n",
    "\n",
    "    film_data = {\n",
    "        'general_data': get_general_film_data(film_soup),\n",
    "        'cast': get_film_cast(film_soup),\n",
    "        'crew': get_film_crew(film_soup),\n",
    "        'details': get_film_details(film_soup),\n",
    "        'genres_and_themes': get_film_genres(film_soup)\n",
    "    }\n",
    "\n",
    "    return film_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops through all URLs in a list, extracting and structuring data from all of them\n",
    "\n",
    "def get_all_films(url_list):\n",
    "    whole_data = []\n",
    "\n",
    "    counter = 0\n",
    "    for film in url_list:\n",
    "        print(f\"Extracting from URL #{counter}:\\n{film}\\n\")\n",
    "        whole_data.append(get_complete_film_data(film))\n",
    "        counter += 1\n",
    "    \n",
    "    return whole_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms the data dictionaries into dataframes\n",
    "\n",
    "def dicts_to_dfs(data):\n",
    "    all_dfs_gdata = [] # general data\n",
    "    all_dfs_cast = []\n",
    "    all_dfs_crew = []\n",
    "    all_dfs_details = []\n",
    "    all_dfs_gthemes = []\n",
    "\n",
    "\n",
    "    for film in data:\n",
    "        id = film['general_data']['letterboxd_id']\n",
    "        title = film['general_data']['letterboxd_shorttitle']\n",
    "        \n",
    "        single_df_gdata = pd.DataFrame.from_dict([film['general_data']])\n",
    "        all_dfs_gdata.append(single_df_gdata)\n",
    "\n",
    "        single_df_cast = pd.DataFrame.from_dict(film['cast']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_cast.append(single_df_cast)\n",
    "\n",
    "        single_df_crew = pd.DataFrame.from_dict(film['crew']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_crew.append(single_df_crew)\n",
    "\n",
    "        single_df_details = pd.DataFrame.from_dict(film['details']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_details.append(single_df_details)\n",
    "\n",
    "        single_df_gthemes = pd.DataFrame.from_dict(film['genres_and_themes']).assign(film_id = id, film_title = title)\n",
    "        all_dfs_gthemes.append(single_df_gthemes)\n",
    "\n",
    "    all_dfs_dict = {\n",
    "        'df_gdata': pd.concat(all_dfs_gdata).reset_index(drop=True),\n",
    "        'df_cast': pd.concat(all_dfs_cast).reset_index(drop=True),\n",
    "        'df_crew': pd.concat(all_dfs_crew).reset_index(drop=True),\n",
    "        'df_details': pd.concat(all_dfs_details).reset_index(drop=True),\n",
    "        'df_gthemes': pd.concat(all_dfs_gthemes).reset_index(drop=True)\n",
    "    }\n",
    "\n",
    "    return all_dfs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, create and treat DFs - Film Club Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filmclub_film_urls = get_film_urls_lbxdlist(\"https://letterboxd.com/dromemario/list/fff-film-fueled-friends/\")\n",
    "\n",
    "#filmclub_films_data = get_all_films(film_urls)\n",
    "\n",
    "#all_dfs_dict = dicts_to_dfs(films_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "notfornow = '''\n",
    "df_generaldata = (\n",
    "    all_dfs_dict['df_gdata'][[\n",
    "        'letterboxd_id',\n",
    "        'letterboxd_shorttitle',\n",
    "        'letterboxd_longtitle',\n",
    "        'letterboxd_slug',\n",
    "        'tmdb_id',\n",
    "        'release_year',\n",
    "        'duration',\n",
    "        'avg_rating',\n",
    "        'letterboxd_url',\n",
    "        'tmdb_url',\n",
    "        'imdb_url'\n",
    "        ]]\n",
    "    .astype({\n",
    "        'release_year': 'int64',\n",
    "        'duration': 'int64',\n",
    "        'avg_rating': 'float64',\n",
    "        'letterboxd_url': 'string',\n",
    "        'tmdb_url': 'string',\n",
    "        'imdb_url': 'string'\n",
    "        })\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_cast = (\n",
    "    all_dfs_dict['df_cast'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'link',\n",
    "        'character_name'\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_cast']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_crew = (\n",
    "    all_dfs_dict['df_crew'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'role',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_crew']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_details = (\n",
    "    all_dfs_dict['df_details'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'key',\n",
    "        'value',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_details']['link'])\n",
    "    .reset_index(drop=True)\n",
    "    .astype({'link': 'string'})\n",
    ")\n",
    "\n",
    "df_genresthemes = (\n",
    "    all_dfs_dict['df_gthemes'].rename(columns={0: 'value'})[[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'value'\n",
    "    ]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "notfornowagain = '''\n",
    "df_generaldata.to_csv(f'{FILMCLUB_FOLDER}fc_generaldata.csv', sep=';', index=False)\n",
    "df_cast.to_csv(f'{FILMCLUB_FOLDER}fc_cast.csv', sep=';', index=False)\n",
    "df_crew.to_csv(f'{FILMCLUB_FOLDER}fc_crew.csv', sep=';', index=False)\n",
    "df_details.to_csv(f'{FILMCLUB_FOLDER}fc_details.csv', sep=';', index=False)\n",
    "df_genresthemes.to_csv(f'{FILMCLUB_FOLDER}fc_genresthemes.csv', sep=';', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, create and treat DFs - Single User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting page 1 out of 16.\n",
      "Extracting page 2 out of 16.\n",
      "Extracting page 3 out of 16.\n",
      "Extracting page 4 out of 16.\n",
      "Extracting page 5 out of 16.\n",
      "Extracting page 6 out of 16.\n",
      "Extracting page 7 out of 16.\n",
      "Extracting page 8 out of 16.\n",
      "Extracting page 9 out of 16.\n",
      "Extracting page 10 out of 16.\n",
      "Extracting page 11 out of 16.\n",
      "Extracting page 12 out of 16.\n",
      "Extracting page 13 out of 16.\n",
      "Extracting page 14 out of 16.\n",
      "Extracting page 15 out of 16.\n",
      "Extracting page 16 out of 16.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "user_film_urls = get_film_urls_lbxduser('dromemario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from URL #0:\n",
      "/film/this-is-the-zodiac-speaking-2024/\n",
      "\n",
      "Extracting from URL #1:\n",
      "/film/endurance-2024/\n",
      "\n",
      "Extracting from URL #2:\n",
      "/film/an-invisible-victim-the-eliza-samudio-case/\n",
      "\n",
      "Extracting from URL #3:\n",
      "/film/im-still-here-2024/\n",
      "\n",
      "Extracting from URL #4:\n",
      "/film/rebel-ridge/\n",
      "\n",
      "Extracting from URL #5:\n",
      "/film/it-ends-with-us/\n",
      "\n",
      "Extracting from URL #6:\n",
      "/film/a-quiet-place-day-one/\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wholedata \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_films\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_film_urls\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m, in \u001b[0;36mget_all_films\u001b[1;34m(url_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m film \u001b[38;5;129;01min\u001b[39;00m url_list:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting from URL #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcounter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfilm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     whole_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_complete_film_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilm\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m whole_data\n",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m, in \u001b[0;36mget_complete_film_data\u001b[1;34m(film_url)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_complete_film_data\u001b[39m(film_url):\n\u001b[1;32m----> 4\u001b[0m     film_soup \u001b[38;5;241m=\u001b[39m \u001b[43mget_raw_film_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilm_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     film_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral_data\u001b[39m\u001b[38;5;124m'\u001b[39m: get_general_film_data(film_soup),\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m'\u001b[39m: get_film_cast(film_soup),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres_and_themes\u001b[39m\u001b[38;5;124m'\u001b[39m: get_film_genres(film_soup)\n\u001b[0;32m     12\u001b[0m     }\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m film_data\n",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m, in \u001b[0;36mget_raw_film_html\u001b[1;34m(film_url)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_raw_film_html\u001b[39m(film_url):\n\u001b[0;32m      4\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://letterboxd.com\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m film_url\n\u001b[1;32m----> 5\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m      6\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(content, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m soup\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wholedata = get_all_films(user_film_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs_dict = dicts_to_dfs(wholedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dromemario_generaldata = (\n",
    "    all_dfs_dict['df_gdata'][[\n",
    "        'letterboxd_id',\n",
    "        'letterboxd_shorttitle',\n",
    "        'letterboxd_longtitle',\n",
    "        'letterboxd_slug',\n",
    "        'tmdb_id',\n",
    "        'release_year',\n",
    "        'duration',\n",
    "        'avg_rating',\n",
    "        'letterboxd_url',\n",
    "        'tmdb_url',\n",
    "        'imdb_url'\n",
    "        ]]\n",
    "    .astype({\n",
    "        'release_year': 'int64',\n",
    "        'duration': 'int64',\n",
    "        'avg_rating': 'float64',\n",
    "        'letterboxd_url': 'string',\n",
    "        'tmdb_url': 'string',\n",
    "        'imdb_url': 'string'\n",
    "        })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dromemario_cast = (\n",
    "    all_dfs_dict['df_cast'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'link',\n",
    "        'character_name'\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_cast']['link'])\n",
    "    .astype({'link': 'string'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dromemario_crew = (\n",
    "    all_dfs_dict['df_crew'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'name',\n",
    "        'role',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_crew']['link'])\n",
    "    .astype({'link': 'string'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dromemario_details = (\n",
    "    all_dfs_dict['df_details'][[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'key',\n",
    "        'value',\n",
    "        'link',\n",
    "    ]]\n",
    "    .assign(link = 'letterboxd.com' + all_dfs_dict['df_details']['link'])\n",
    "    .astype({'link': 'string'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dromemario_genresthemes = (\n",
    "    all_dfs_dict['df_gthemes'].rename(columns={0: 'value'})[[\n",
    "        'film_id',\n",
    "        'film_title',\n",
    "        'value'\n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dromemario_generaldata.to_csv(f'{PERSONALPROFILES_FOLDER}dromemario_generaldata.csv', sep=';', index=False)\n",
    "user_dromemario_cast.to_csv(f'{PERSONALPROFILES_FOLDER}dromemario_cast.csv', sep=';', index=False)\n",
    "user_dromemario_crew.to_csv(f'{PERSONALPROFILES_FOLDER}dromemario_crew.csv', sep=';', index=False)\n",
    "user_dromemario_details.to_csv(f'{PERSONALPROFILES_FOLDER}dromemario_details.csv', sep=';', index=False)\n",
    "user_dromemario_genresthemes.to_csv(f'{PERSONALPROFILES_FOLDER}dromemario_genresthemes.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
